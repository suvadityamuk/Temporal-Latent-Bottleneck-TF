{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKcguMbcPs6iN6jqn/By7F"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "nkwpaxcJpkxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "DDhDHOmnpmFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "b9cyhJ-aon6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardNetwork(layers.Layer):\n",
        "    \"\"\"Feed Forward Network.\n",
        "\n",
        "    Args:\n",
        "        dims (`int`): Dimension of the model.\n",
        "        dropout (`float`): Dropout probability.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dims: int, dropout: float = 0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=4*dims, activation=tf.nn.gelu),\n",
        "                layers.Dense(units=dims),\n",
        "                layers.Dropout(rate=dropout),\n",
        "            ]\n",
        "        )\n",
        "        self.add = layers.Add()\n",
        "        self.layernorm = layers.LayerNormalization(epsilon=1e-5)\n",
        "\n",
        "    def call(self, x: tf.Tensor):\n",
        "        x = self.add([x, self.ffn(x)])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class BaseAttention(layers.Layer):\n",
        "    \"\"\"The base attention module.\n",
        "    \n",
        "    Args:\n",
        "        num_heads (`int`): Number of attention heads.\n",
        "        key_dim (`int`): Size of each attention head for query and key.\n",
        "        dropout (`float`): Dropout probability.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads: int, key_dim: int, dropout: float = 0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.mha = layers.MultiHeadAttention(num_heads, key_dim, dropout=dropout)\n",
        "        self.layernorm = layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.add = layers.Add()\n",
        "\n",
        "\n",
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, x: tf.Tensor, context: tf.Tensor):\n",
        "        (attention_outs, attention_scores) = self.mha(\n",
        "            query=x,\n",
        "            key=context,\n",
        "            value=context,\n",
        "            return_attention_scores=True,\n",
        "        )\n",
        "        self.last_attention_scores = attention_scores\n",
        "        x = self.add([x, attention_outs])\n",
        "        x = self.layernorm(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SelfAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        (attention_outputs, attention_scores) = self.mha(\n",
        "            query=x,\n",
        "            key=x,\n",
        "            value=x,\n",
        "            return_attention_scores=True,\n",
        "        )\n",
        "        self.last_attention_scores = attention_scores\n",
        "        x = self.add([x, attention_outputs])\n",
        "        x = self.layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ODl3BH9zopTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptual Module"
      ],
      "metadata": {
        "id": "PD8IhdZ5ohI-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal Latent Bottleneck Model"
      ],
      "metadata": {
        "id": "jBqNQOs7ojMe"
      }
    }
  ]
}